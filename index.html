<!DOCTYPE html>
<html lang="en">
<head>
    <title>Łukasz Korycki</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./css/academicons.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <link rel="stylesheet" href="./css/main.css" />

    <script src="https://kit.fontawesome.com/168639ce6f.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
</head>

<body id="body" data-spy="scroll" data-target=".navbar" data-offset="300">

    <nav class="navbar navbar-default navbar-fixed-top slideanim-hor-init-rev">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#home">Łukasz Korycki</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#home">HOME</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#about">ABOUT</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#events">EVENTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#research">RESEARCH</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#projects">PROJECTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="data/Korycki_resume.pdf" target="_blank">CV</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="jumbotron" id="home">
        <div class="row">
            <div class="text-center">
                <div class="intro-anim-header delay200"><h1 style="letter-spacing: 0.5px;">Łukasz Korycki</h1>
                <h3>PhD Student in ML/AI & Data Engineer</h3></div>
                <br>
                <a href="https://www.linkedin.com/in/%C5%82ukasz-korycki-6062ab195/" target="_blank">
                    <i class="fab fa-linkedin intro-anim-header delay100off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://www.researchgate.net/profile/Lukasz_Korycki2" target="_blank">
                    <i class="ai ai-researchgate-square intro-anim-header delay200off fa-fade" style="font-size:48px;color:#22e5a4"></i></a></a>
                <a href="https://scholar.google.com/citations?user=cLtlBLgAAAAJ&hl=en" target="_blank">
                    <i class="ai ai-google-scholar-square intro-anim-header delay300off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://twitter.com" target="_blank">
                    <i class="fa fa-twitter-square intro-anim-header delay400off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://github.com/lkorycki" target="_blank">
                    <i class="fa fa-github-square intro-anim-header delay500off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="mailto:korycki.lukas@gmail.com" target="_blank">
                    <i class="fa fa-envelope-square intro-anim-header delay600off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
            </div>
        </div>
    </div>

    <div id="about" class="container-fluid slideanim-hor-init">
        <div class="row">
            <div class="col-sm-6 col-sm-offset-2" style="padding-left: 50px">
                <div class="major"><h2>About Me</h2></div>
                <h4>I am a 3rd year Ph.D. student in the Machine Learning and Data Stream Mining Lab at Virginia Commonwealth University (Richmond, USA), working under Dr. Bartosz Krawczyk.
                    <br><br>
                    In my research, I am focused on lifelong/continual learning from stationary and non-stationary data. I have published works on online active and semi-supervised learning, effective concept drift adaptation, change detection and dynamic imbalance.
                    Most recently, I have been dedicated to the problem of catastrophic forgetting and efficient knowledge aggregation in deep neural networks with applications to computer vision.
                    <br><br>
                    Before starting my Ph.D., I was a software and data engineer at Nokia in the Big Data & Network Engineering department, where I gained experience in developing commercial data-driven projects.
                </h4>
            </div>

            <div class="col-sm-2">
                <br><br><br><br><br>
                <span class="photo"><img src="images/photo.png"></span>
            </div>

        </div>
    </div>

    <div id="events" class="container-fluid bg-grey">
        <div class="row slideanim-hor">
            <div class="col-sm-8 col-sm-offset-2">
                <div class="major center"><h2>Events</h2></div>
            </div>
        </div>

        <div class="page slideanim-hor">
            <div class="timeline">

<!--                <div class="timeline__group">-->
<!--                    <span class="timeline__year">Now</span>-->
<!--                </div>-->

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Received a conference registration grant and was accepted to the early career mentoring program at IJCNN!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">20</span>
                            <span class="timeline__month">Mar</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams target="_blank">"Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"</a> was accepted for presentation at IJCNN 2020!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2020</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">16</span>
                            <span class="timeline__month">Dec</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Passed the Ph.D. Qualifying Exam.</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">06</span>
                            <span class="timeline__month">Oct</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank">"Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2019 (acceptance rate: 18.7%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">27</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8964214 target="_blank">"Unsupervised Drift Detector Ensembles for Data Stream Mining"</a> was accepted for presentation at IEEE DSAA 2019 (acceptance rate: 29.4%)!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2019</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">28</span>
                            <span class="timeline__month">Aug</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank">"Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2018 (acceptance rate: 18.9%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jan</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Started working in the Machine Learning and Data Stream Mining Lab at Virginia Commonwealth University (Richmond, USA) under Dr. Bartosz Krawczyk.</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2018</span>
                </div>
            </div>
        </div>

    </div>

    <div id="research">
        <div class="container-fluid">
            <div class="major center slideanim-hor"><h2>Research</h2></div>

            <div class="row slideanim-hor">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/os_imb.png" class="thumbnail img-responsive"
                                                alt="Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        In this paper, we propose a novel framework for learning from multi-class imbalanced data streams that simultaneously tackles three major problems in this area: (i) changing imbalance ratios among multiple classes; (ii) concept drift; and (iii) limited access to ground truth. We use active learning combined with streaming-based oversampling that uses both information about current class ratios and classifier errors on each class to create new instances in a meaningful way. Conducted experimental study shows that our single-classifier framework is capable of outperforming state-of-the-art ensembles dedicated to multi-class imbalanced data streams in both fully supervised and sparsely labeled learning scenarios.                    </h4>
                    <h4 class="text-danger"><strong> International Joint Conference on Neural Networks (IJCNN), Glasgow, UK, 2020. </strong><br>
                        <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button">BibTex</button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/abst4.png" class="thumbnail img-responsive"
                                                alt="Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/document/9006453" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, A.Cano, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">When dealing with classification tasks, one has to remember that effective adaptation has to be achieved on weak foundations of partially labeled and often imbalanced data. In our work, we propose an online framework for binary classification, that aims to handle the complex problem of working with dynamic, sparsely labeled and imbalanced streams. The main part of it is a novel active learning strategy (MD-OAL) that is able to prioritize labeling of minority instances and, as a result, improve the balance of the learning process. We combine the strategy with a dynamic ensemble of base learners that can abstain from making decisions, if they are very uncertain. We adjust the abstaining mechanism in favor of minority instances, providing an effective method for handling remaining imbalance and a concept drift simultaneously. The conducted evaluation shows that in the challenging and realistic scenarios our framework outperforms state-of-the-art algorithms, providing higher resilience to the combined effect of limited labeling and imbalance.</h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button">BibTex</button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/ens_det.jpg" class="thumbnail img-responsive"
                                                alt="Unsupervised Drift Detector Ensembles for Data Stream Mining"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Unsupervised Drift Detector Ensembles for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Supervised streaming machine learning algorithms require a certain number of labeled instances in order to stay up-to-date. Since high budgets dedicated for this purpose are usually infeasible, we have to limit the supervision as much as we can. One possible approach is to trigger labeling, only if a change is explicitly indicated by a detector. While there are several supervised algorithms dedicated for this purpose, the more practical unsupervised ones are still lacking a proper attention. In this paper, we propose a novel unsupervised ensemble drift detector that recognizes local changes in feature subspaces (EDFS) without additional supervision, using specialized committees of incremental Kolmogorov-Smirnov tests. We combine it with an adaptive classifier and update it, only if the drift detector signalizes a change. Conducted experiments show that our framework is able to efficiently adapt to various concept drifts and outperform other unsupervised algorithms.
                    </h4>
                    <h4 class="text-danger"><strong> IEEE International Conference on Data Science and Advanced Analytics DSAA, Washington, D.C., USA, 2019.</strong><br>
                        <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button">BibTex</button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/clust_divers.jpg" class="thumbnail img-responsive"
                                                alt="Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/document/8622038" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams</strong><br>
                        <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a><h4 class="h4-small">
                        Due to their  predictive  power  and  capabilities  for  handling  evolving data, ensemble approaches have proven themselves to be highly effective in data stream mining. One  of  the  key  aspects  of  ensemble  learning  is  diversity among  base  classifiers  –  it  improves  accuracy  and  allows  for anticipating  and  recovering  from  concept  drifts.  It  has  been shown that while diversity is desirable during changes, it may impede  learning  when  data  becomes  stationary.  In  this  paper, we  present  a  novel  ensemble  technique  that  exploits  the  idea of  dynamic  diversification,  which  increases  diversity  during changes  and  reduces  it  when  a  stream  becomes  stable.  The algorithm uses online clustering for this task by creating locally specialized base learners trained on spatially related instances. Three control strategies based on the novel range heuristic for managing  a  trade-off  between  error  (a  change  indicator)  and diversity are utilized. Additionally, two intensification strategies are  proposed  for  exploitation  of  newly  arriving  instances,  allowing for faster adaptation. Experimental study evaluates the general performance and diversity of the proposed algorithm, proving its capabilities to outperform state-of-the-art ensembles dedicated  to  drifting  data  stream  mining.</h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Seattle, WA, USA, 2018.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button">BibTex</button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/alsl2.png" class="thumbnail img-responsive"
                                                alt="Combining Active Learning and Self-Labeling for Data Stream Mining"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Combining Active Learning and Self-Labeling for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">In this work we concentrate on the issue of actual availability of true class labels. The assumption that the ground truth for each instance becomes known right after processing it is far from being realistic, due to usually high costs connected with its acquisition. Active learning is an attractive solution to this problem, as it selects most valuable instances for labeling. In this paper, we propose to augment the active learning module with self-labeling approach. This allows classifier to automatically label instances for which it displays the highest certainty and use them for further training. Although in this preliminary work we use a static threshold for self-labeling, the obtained results are encouraging. Our experimental study shows that this approach complements the active learning strategy and allows to improve data stream classification, especially in scenarios with very small labeling budget.</h4>
                    <h4 class="text-danger"><strong>International Conference on Computer Recognition Systems (CORES), Wrocław, Poland, 2017.</strong><br>
                        <a href=https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button">BibTex</button>
                    </h4>
                    <br>
                </div>
            </div>

        </div>
    </div>

    <div id="projects" class="container-fluid bg-grey">
        <div class="major center slideanim-hor"><h2>PROJECTS</h2></div>
        <div class="row slideanim-hor">
            <h1 class="text-center">Coming soon!</h1><br>
        </div>
    </div>

    <footer class="container-fluid text-center">
        <script>
            $(document).ready(function () {
                $(".navbar a, footer a[href='#home']").on('click', function (event) {
                    var hash = this.hash;
                    if (hash != "") {
                        event.preventDefault();
                    }

                    $('html, body').stop().animate({
                        scrollTop: $(hash).offset().top
                    }, 900, function () {
                        // window.location.hash = hash;
                    });
                });

                $(window).scroll(function () {
                    $(".slideanim-vert").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-vert");
                        }
                    });

                    $(".slideanim-hor").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-hor");
                        }
                    });
                });

                $(".slideanim-hor-init").each(async function () {
                    await new Promise(r => setTimeout(r, 400));
                    $(this).addClass("slide-hor");
                });

                $(".slideanim-hor-init-rev").each(async function () {
                    await new Promise(r => setTimeout(r, 400));
                    $(this).addClass("slide-hor-rev");
                });
            })
        </script>

        <a href="#home" title="Home">
            <span class="glyphicon glyphicon-home" style="font-size: 40px; color:white"></span>
        </a>
        <hr>
    </footer>

</body>
</html>
