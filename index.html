<!DOCTYPE html>
<html lang="en">
<head>
    <title>Łukasz Korycki - ML/AI & Data Engineering</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="machine learning, deep learning, AI, artificial intelligence, Lukasz Korycki, data streams, VCU, PhD, data engineer, data, computer vision, Nokia">
    <meta name="author" content="Lukasz Korycki">
    <meta property="og:image" content="https://lukaszkorycki.com/images/photo.jpg"/>
    <meta name="description" content="A motivated Ph.D. student conducting research in ML/AI. At the same time, a software and data engineer with relevant experience from the big data industry.">

    <link rel="stylesheet" href="./css/academicons.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <link rel="stylesheet" href="./css/main.css" />
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">

    <script src="https://kit.fontawesome.com/168639ce6f.js" crossorigin="anonymous"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.10/clipboard.min.js"></script>
</head>

<body id="body" data-spy="scroll" data-target=".navbar" data-offset="300">

    <div class="loader-wrapper">
        <span class="loader"><span class="loader-inner"></span></span>
    </div>

    <nav class="navbar navbar-default navbar-fixed-top slideanim-hor-init-rev">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#home">Łukasz Korycki</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#home">HOME</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#about">ABOUT</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#events">EVENTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#research">RESEARCH</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#projects">PROJECTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="data/Korycki_resume.pdf" target="_blank">CV</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="jumbotron" id="home">
        <div class="row">
            <div class="text-center">
                <div class="intro-anim-header delay200"><h1 style="letter-spacing: 0.5px;">Łukasz Korycki</h1>
                <h3>Ph.D. in ML/AI & Data Engineer</h3></div>
                <br>
                <a href="https://www.linkedin.com/in/lkorycki/" target="_blank">
                    <i class="fab fa-linkedin intro-anim-header delay100off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://www.researchgate.net/profile/Lukasz_Korycki2" target="_blank">
                    <i class="ai ai-researchgate-square intro-anim-header delay200off fa-fade" style="font-size:48px;color:#22e5a4"></i></a></a>
                <a href="https://scholar.google.com/citations?user=cLtlBLgAAAAJ&hl=en" target="_blank">
                    <i class="ai ai-google-scholar-square intro-anim-header delay300off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://twitter.com/KoryckiLukasz" target="_blank">
                    <i class="fa fa-twitter-square intro-anim-header delay400off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://github.com/lkorycki" target="_blank">
                    <i class="fa fa-github-square intro-anim-header delay500off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="mailto:korycki.lukas@gmail.com" target="_blank">
                    <i class="fa fa-envelope-square intro-anim-header delay600off fa-fade" style="font-size:48px;color:#22e5a4"></i></a>
            </div>
        </div>
    </div>

    <div id="about" class="container-fluid slideanim-hor-init">
        <div class="row">
            <div class="col-sm-6 col-sm-offset-2" style="padding: 0 50px">
                <div class="major"><h2>About Me</h2></div>
                <h4>I am a research scientist at Meta (Silicon Valley, USA), with Ph.D. in ML/AI. Mostly a generalist, devoted to developing universal approaches and supporting their applications to real-world issues. Specialized in advancing online/incremental learning algorithms that are able to effectively aggregate stable patterns and adapt to changes in dynamic environments.
                    <br><br>
                    In my Ph.D. research, I have been focused on continual/lifelong learning from stationary and non-stationary data, mainly in the context of catastrophic forgetting and concept drift adaptation.
                    <br><br>
                    Besides my academic experience, I was a SWE/ML intern at Facebook, working with the Ads Core ML team on large-scale entity relation classification using semantic and graph embeddings. Before starting my Ph.D., I was a software/data engineer at Nokia, in the Big Data & Network Engineering department, where I gained experience in developing commercial data-driven projects.
                </h4>
            </div>

            <div class="col-sm-2">
                <br><br><br><br><br><br><br>
                <div class="photo"><img src="images/photo.jpg"></div>
            </div>

        </div>
    </div>

    <div id="events" class="container-fluid bg-grey">
        <div class="row slideanim-hor">
            <div class="col-sm-8 col-sm-offset-2">
                <div class="major center"><h2>Events</h2></div>
            </div>
        </div>

        <div class="page slideanim-hor">
            <div class="timeline">
                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">13</span>
                            <span class="timeline__month">June</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Started my job as a research scientist at Meta!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">05</span>
                            <span class="timeline__month">May</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Successfully defended my Ph.D. thesis dissertation!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">25</span>
                            <span class="timeline__month">Apr</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our journal paper <a href=https://www.sciencedirect.com/science/article/abs/pii/S0031320322002308 target="_blank">
                                    "Instance Exploitation for Learning Temporary Concepts from Sparsely Labeled Drifting Data Streams"</a> was accepted for publication in Pattern Recognition!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">12</span>
                            <span class="timeline__month">Apr</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our journal paper <a href=https://www.semanticscholar.org/paper/Adversarial-Concept-Drift-Detection-under-Poisoning-Korycki-Krawczyk/f531093e7b22abe27ae9af2ee67fbc43f2957705 target="_blank">
                                    "Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining"</a> was accepted for publication in Machine Learning!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">28</span>
                            <span class="timeline__month">Jan</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Received Graduate School Dissertation Assistantship for Spring 2022!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2022</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">01</span>
                            <span class="timeline__month">Dec</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Successfully defended my Ph.D. proposal and proceeded to doctoral candidacy!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">18</span>
                            <span class="timeline__month">Jun</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_1050.pdf target="_blank">"Streaming Decision Trees for Lifelong Learning"</a> was accepted for publication at ECML PKDD 2021 (rank: A)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">24</span>
                            <span class="timeline__month">May</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Started my SWE/ML internship at Facebook!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">19</span>
                            <span class="timeline__month">Apr</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Won the 2020-2021 Outstanding Paper Award (at VCU) for <a href=https://www.researchgate.net/publication/349253910_Concept_Drift_Detection_from_Multi-Class_Imbalanced_Data_Streams target="_blank">"Concept Drift Detection from Multi-Class Imbalanced Data Streams"</a>!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">13</span>
                            <span class="timeline__month">Apr</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://www.researchgate.net/publication/351010268_Class-Incremental_Experience_Replay_for_Continual_Learning_under_Concept_Drift target="_blank">"Class-Incremental Experience Replay for Continual Learning under Concept Drift"</a> was accepted for publication at the CVPR 2021 Workshop on Continual Learning!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">07</span>
                            <span class="timeline__month">Apr</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>In recent months, I have had multiple opportunities to support several conferences and journals by serving as a reviewer for: ECML/PKDD, CVPRW, IJCNN, IEEE Transactions NNLS/SMC.</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">09</span>
                            <span class="timeline__month">Feb</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>And our paper <a href=https://www.researchgate.net/publication/349253910_Concept_Drift_Detection_from_Multi-Class_Imbalanced_Data_Streams target="_blank">"Concept Drift Detection from Multi-Class Imbalanced Data Streams"</a> was accepted for presentation at ICDE 2021 (rank: A*)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Feb</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://www.researchgate.net/publication/349254127_Low-Dimensional_Representation_Learning_from_Imbalanced_Data_Streams target="_blank">"Low-Dimensional Representation Learning from Imbalanced Data Streams"</a> was accepted for presentation at PAKDD 2021 (rank: A)!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2021</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">21</span>
                            <span class="timeline__month">Sep</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>We made two of our ongoing journal papers available on arXiv:
                                    <a href=https://arxiv.org/abs/2009.09382 target="_blank">
                                        "Instance Exploitation for Learning Temporary Concepts from Sparsely Labeled Drifting Data Streams"</a> and
                                    <a href=https://arxiv.org/abs/2009.09497 target="_blank">
                                        "Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining"</a>.
                                </p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Received a conference registration grant and was accepted to the early career mentoring program at IJCNN!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">20</span>
                            <span class="timeline__month">Mar</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams target="_blank">"Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"</a> was accepted for presentation at IJCNN 2020 (rank: A)!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2020</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">16</span>
                            <span class="timeline__month">Dec</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Passed the Ph.D. Qualifying Exam.</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">06</span>
                            <span class="timeline__month">Oct</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank">"Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2019 (acceptance rate: 18.7%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">27</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8964214 target="_blank">"Unsupervised Drift Detector Ensembles for Data Stream Mining"</a> was accepted for presentation at IEEE DSAA 2019 (acceptance rate: 29.4%)!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2019</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">28</span>
                            <span class="timeline__month">Aug</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank">"Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2018 (acceptance rate: 18.9%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jan</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Started working in the Machine Learning and Data Stream Mining Lab at Virginia Commonwealth University (Richmond, USA) under Dr. Bartosz Krawczyk.</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2018</span>
                </div>
            </div>
        </div>

    </div>

    <div id="research">
        <div class="container-fluid">
            <div class="major center slideanim-hor"><h2>Research</h2></div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/inst-exploit-3.png" class="thumbnail img-responsive"
                                                     alt="Instance Exploitation for Learning Temporary Concepts from Sparsely Labeled Drifting Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322002308" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Instance Exploitation for Learning Temporary Concepts from Sparsely Labeled Drifting Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Dealing with dynamic and everlasting problems poses new challenges for which traditional batch-based offline algorithms turn out to be insufficient in terms of computational time and predictive performance. One of the most crucial limitations is that we cannot assume having access to a finite and complete data set - we always have to be ready for new data that may complement our model. This poses a critical problem of providing labels for potentially unbounded streams. In the real world, we are forced to deal with very strict budget limitations, therefore, we will most likely face the scarcity of annotated instances, which are essential in supervised learning. In our work, we emphasize this problem and propose a novel instance exploitation technique. We show that when: (i) data is characterized by temporary non-stationary concepts, and (ii) there are very few labels spanned across a long time horizon, it is actually better to risk overfitting and adapt models more aggressively by exploiting the only labeled instances we have, instead of sticking to a standard learning mode and suffering from severe underfitting. We present different strategies and configurations for our methods, as well as an ensemble algorithm that attempts to maintain a sweet spot between risky and normal adaptation. Finally, we conduct a complex in-depth comparative analysis of our methods, using state-of-the-art streaming algorithms relevant to the given problem.
                    </h4>
                    <h4 class="text-danger"><strong>Pattern Recognition, 2022.</strong><br>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322002308" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@article{Korycki:2022exp, title = {Instance exploitation for learning temporary concepts from sparsely labeled drifting data streams}, journal = {Pattern Recognition}, volume = {129}, pages = {108749}, year = {2022}, issn = {0031-3203}, doi = {https://doi.org/10.1016/j.patcog.2022.108749}, author = {{\L}ukasz Korycki and Bartosz Krawczyk}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/lldt1.png" class="thumbnail img-responsive"
                                                     alt="Streaming Decision Trees for Lifelong Learning"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-86486-6_31" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Streaming Decision Trees for Lifelong Learning</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Comprehensive studies focused on incremental neural networks have shown that these models tend to struggle with remembering previously learned patterns. This issue known as catastrophic forgetting has been widely studied and addressed by several different approaches. At the same time, almost no research has been conducted on online decision trees in the same setting. In this work, we identify the problem by showing that streaming decision trees (i.e., Hoeffding Trees) fail at providing reliable long-term learning in class-incremental scenarios, which can be further generalized to learning under temporal imbalance. By proposing a streaming class-conditional attribute estimation, we attempt to solve this vital problem at its root, which, ironically, lies in leaves. Through a detailed experimental study we show that, in the given scenario, even a rough estimate based on previous conditional statistics and current class priors can significantly improve the performance of streaming decision trees, preventing them from catastrophically forgetting earlier concepts, which do not appear for a long time or even ever again.                    </h4>
                    <h4 class="text-danger"><strong>The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2021), Bilbao, Spain, 2021.</strong><br>
                        <a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-86486-6_31" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@inproceedings{Korycki:2021lldt, author = {Korycki, {\L}ukasz and Krawczyk, Bartosz}, title = {Streaming Decision Trees for Lifelong Learning}, year = {2021}, isbn = {978-3-030-86485-9}, doi = {10.1007/978-3-030-86486-6_31}, booktitle = {Machine Learning and Knowledge Discovery in Databases. Research Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part I}, pages = {502–518}, numpages = {17}, location = {Bilbao, Spain}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/er.png" class="thumbnail img-responsive"
                                                     alt="Class-Incremental Experience Replay for Continual Learning under Concept Drift"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://www.semanticscholar.org/paper/Class-Incremental-Experience-Replay-for-Continual-Korycki-Krawczyk/7f160841319fd790e01804eb2049bb0ea66d69c9" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Class-Incremental Experience Replay for Continual Learning under Concept Drift</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Modern machine learning systems need to be able to cope with constantly arriving and changing data. Two main areas of research dealing with such scenarios are continual learning and data stream mining. Continual learning focuses on accumulating knowledge and avoiding forgetting, assuming information once learned should be stored. Data stream mining focuses on adaptation to concept drift and discarding outdated information, assuming that only the most recent data is relevant. While these two areas are mainly being developed in separation, they offer complementary views on the problem of learning from dynamic data. There is a need for unifying them, by offering architectures capable of both learning and storing new information, as well as revisiting and adapting to changes in previously seen concepts. We propose a novel continual learning approach that can handle both tasks. Our experience replay method is fueled by a centroid-driven memory storing diverse instances of incrementally arriving classes. This is enhanced with a reactive subspace buffer that tracks concept drift occurrences in previously seen classes and adapts clusters accordingly. The proposed architecture is thus capable of both remembering valid and forgetting outdated information, offering a holistic framework for continual learning under concept drift.
                    </h4>
                    <h4 class="text-danger"><strong>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, Nashville, USA, 2021.</strong><br>
                        <a href="https://www.semanticscholar.org/paper/Class-Incremental-Experience-Replay-for-Continual-Korycki-Krawczyk/7f160841319fd790e01804eb2049bb0ea66d69c9" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@article{Korycki:2021rsb, title={Class-Incremental Experience Replay for Continual Learning under Concept Drift}, author={{\L}ukasz Korycki and Bartosz Krawczyk}, journal={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, year={2021}, pages={3644-3653}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/imb_det_boltz.png" class="thumbnail img-responsive"
                                                     alt="Concept Drift Detection from Multi-Class Imbalanced Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://www.semanticscholar.org/paper/Concept-Drift-Detection-from-Multi-Class-Imbalanced-Korycki-Krawczyk/0afe794ae118d45b5e28634cc86fbf73d7df719c" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Concept Drift Detection from Multi-Class Imbalanced Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        While there exists a plethora of drift detectors, all of them assume that we are dealing with roughly balanced classes. In the case of imbalanced data streams, those detectors will be biased towards the majority classes, ignoring changes happening in the minority ones. Furthermore, class imbalance may evolve over time and classes may change their roles (majority becoming minority and vice versa). This is especially challenging in the multi-class setting, where relationships among classes become complex. In this paper, we propose a detailed taxonomy of challenges posed by concept drift in multi-class imbalanced data streams, as well as a novel trainable concept drift detector based on Restricted Boltzmann Machine. It is capable of monitoring multiple classes at once and using reconstruction error to detect changes in each of them independently. Our detector utilizes a skew-insensitive loss function that allows it to handle multiple imbalanced distributions. Due to its trainable nature, it is capable of following changes in a stream and evolving class roles, as well as it can deal with local concept drift occurring in minority classes. Extensive experimental study on multi-class drifting data streams, enriched with a detailed analysis of the impact of local drifts and changing imbalance ratios, confirms the high efficacy of our approach.
                    </h4>
                    <h4 class="text-danger"><strong>37th IEEE International Conference on Data Engineering (ICDE), Crete, Greece, 2021.</strong><br>
                        <a href="https://www.semanticscholar.org/paper/Concept-Drift-Detection-from-Multi-Class-Imbalanced-Korycki-Krawczyk/0afe794ae118d45b5e28634cc86fbf73d7df719c" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@article{Korycki:2021imbdet, title={Concept Drift Detection from Multi-Class Imbalanced Data Streams}, author={{\L}ukasz Korycki and Bartosz Krawczyk}, journal={2021 IEEE 37th International Conference on Data Engineering (ICDE)}, year={2021}, pages={1068-1079}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/low_rep_imb.png" class="thumbnail img-responsive"
                                                     alt="Low-Dimensional Representation Learning from Imbalanced Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-75762-5_50" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Low-Dimensional Representation Learning from Imbalanced Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        We propose a novel ensemble approach, where each new base classifier is built using a low-dimensional embedding. We use class-dependent entropy linear manifold to find the most discriminative low-dimensional representation that is, at the same time, skew-insensitive. This allows us to address two challenging issues: (i) learning efficient classifiers from imbalanced and drifting streams without data resampling; and (ii) tackling simultaneously high-dimensional and imbalanced streams that pose extreme challenges to existing classifiers. Our proposed low-dimensional representation algorithm is a flexible plug-in that can work with any ensemble learning algorithm, making it a highly useful tool for difficult scenarios of learning from high-dimensional imbalanced and drifting data streams.
                    </h4>
                    <h4 class="text-danger"><strong>25th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), Delhi, India, 2021.</strong><br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-030-75762-5_50" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@InProceedings{Korycki:2021low, author={Korycki, {\L}ukasz and Krawczyk, Bartosz}, title={Low-Dimensional Representation Learning from Imbalanced Data Streams}, booktitle={Advances in Knowledge Discovery and Data Mining}, year={2021}, pages={629--641}, isbn={978-3-030-75762-5}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/attck-det-2.png" class="thumbnail img-responsive"
                                                     alt="Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://arxiv.org/abs/2009.09497" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        When dealing with data streams one must consider the possibility of a malicious injection of false data that simulates a concept drift. This adversarial setting assumes a poisoning attack that may be conducted in order to damage the underlying classification system by forcing adaptation to false data. Existing drift detectors are not capable of differentiating between real and adversarial concept drift. In this paper, we propose a framework for robust concept drift detection in the presence of adversarial and poisoning attacks. We introduce the taxonomy for two types of adversarial concept drifts, as well as a robust trainable drift detector. It is based on the augmented Restricted Boltzmann Machine with improved gradient computation and energy function. We also introduce Relative Loss of Robustness - a novel measure for evaluating the performance of concept drift detectors under poisoning attacks. Extensive computational experiments, conducted on both fully and sparsely labeled data streams, prove the high robustness and efficacy of the proposed drift detection framework in adversarial scenarios.
                    </h4>
                    <h4 class="text-danger"><strong>Preprint on arXiv, 2020.</strong><br>
                        <a href="https://arxiv.org/abs/2009.09497" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@misc{Korycki:2020adv, author={{\L}. {Korycki} and B. {Krawczyk}}, title={{Adversarial Concept Drift Detection under Poisoning Attacks for Robust Data Stream Mining}}, year={2020}, eprint={2009.09497}, archivePrefix={arXiv}, primaryClass={cs.LG}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/os_imb.png" class="thumbnail img-responsive"
                                                alt="Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Learning from imbalanced data and data stream mining are among the most popular areas in contemporary machine learning. There is a strong interplay between these domains, as data streams are frequently characterized by skewed distributions. However, most of the existing works focus only on binary problems, omitting significantly more challenging multi-class imbalanced data. In this paper, we propose a novel framework for learning from multi-class imbalanced data streams that simultaneously tackles three major problems in this area: (i) changing imbalance ratios among multiple classes, (ii) concept drift, and (iii) limited access to ground truth. We use active learning combined with streaming-based oversampling that uses both information about current class ratios and classifier errors on each class to create new instances in a meaningful way. Conducted experimental study shows that our single-classifier framework is capable of outperforming state-of-the-art ensembles dedicated to multi-class imbalanced data streams in both fully supervised and sparsely labeled learning scenarios.
                    </h4>
                    <h4 class="text-danger"><strong>International Joint Conference on Neural Networks (IJCNN), Glasgow, UK, 2020.</strong><br>
                        <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text="@InProceedings{Korycki:2020, author={{\L}. {Korycki} and B. {Krawczyk}}, booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams}, year={2020}, volume={}, number={}, pages={1-8}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/abst4.png" class="thumbnail img-responsive"
                                                alt="Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/document/9006453" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, A.Cano, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        When dealing with classification tasks, one has to remember that effective adaptation has to be achieved on weak foundations of partially labeled and often imbalanced data. In our work, we propose an online framework for binary classification, that aims to handle the complex problem of working with dynamic, sparsely labeled and imbalanced streams. The main part of it is a novel active learning strategy (MD-OAL) that is able to prioritize the labeling of minority instances and, as a result, improve the balance of the learning process. We combine the strategy with a dynamic ensemble of base learners that can abstain from making decisions if they are very uncertain. We adjust the abstaining mechanism in favor of minority instances, providing an effective method for handling remaining imbalance and concept drift simultaneously. The conducted evaluation shows that in the challenging and realistic scenarios our framework outperforms state-of-the-art algorithms, providing higher resilience to the combined effect of limited labeling and imbalance.
                    </h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text=
                                "@InProceedings{Korycki:2019alimb, author={{\L}. {Korycki} and A. {Cano} and B. {Krawczyk}}, booktitle={{2019 IEEE International Conference on Big Data (Big Data)}}, title={{Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams}}, year={2019}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/ens_det.jpg" class="thumbnail img-responsive"
                                                alt="Unsupervised Drift Detector Ensembles for Data Stream Mining"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Unsupervised Drift Detector Ensembles for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Supervised streaming machine learning algorithms require a certain number of labeled instances in order to stay up-to-date. Since high budgets dedicated to this purpose are usually infeasible, we have to limit the supervision as much as we can. One possible approach is to trigger labeling only if a change is explicitly indicated by a detector. While there are several supervised algorithms designed for this purpose, the more practical unsupervised ones are still lacking proper attention. In this paper, we propose a novel unsupervised ensemble drift detector that recognizes local changes in feature subspaces (EDFS) without additional supervision, using specialized committees of incremental Kolmogorov-Smirnov tests. We combine it with an adaptive classifier and update it only if the drift detector signalizes a change. Conducted experiments show that our framework is able to efficiently adapt to various concept drifts and outperform other unsupervised algorithms.
                    </h4>
                    <h4 class="text-danger"><strong> IEEE International Conference on Data Science and Advanced Analytics (DSAA), Washington, D.C., USA, 2019.</strong><br>
                        <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text=
                                "@InProceedings{Korycki:2019ensdet, author={{\L}. {Korycki} and B. {Krawczyk}}, booktitle={{2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}}, title={{Unsupervised Drift Detector Ensembles for Data Stream Mining}}, year={2019}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/clust_divers.jpg" class="thumbnail img-responsive"
                                                alt="Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://ieeexplore.ieee.org/document/8622038" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams</strong><br>
                        <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Due to their  predictive  power  and  capabilities  for  handling  evolving data, ensemble approaches have proven themselves to be highly effective in data stream mining. One  of  the  key  aspects  of  ensemble  learning  is  diversity among  base  classifiers  –  it  improves  accuracy  and  allows  for anticipating  and  recovering  from  concept  drifts.  It  has  been shown that while diversity is desirable during changes, it may impede  learning  when  data  becomes  stationary.  In  this  paper, we  present  a  novel  ensemble  technique  that  exploits  the  idea of  dynamic  diversification,  which  increases  diversity  during changes  and  reduces  it  when  a  stream  becomes  stable.  The algorithm uses online clustering for this task by creating locally specialized base learners trained on spatially related instances. Three control strategies based on the novel range heuristic for managing  a  trade-off  between  error  (a  change  indicator)  and diversity are utilized. Additionally, two intensification strategies are  proposed  for  exploitation  of  newly  arriving  instances,  allowing for faster adaptation. Experimental study evaluates the general performance and diversity of the proposed algorithm, proving its capabilities to outperform state-of-the-art ensembles dedicated  to  drifting  data  stream  mining.
                    </h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Seattle, WA, USA, 2018.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text=
                                "@InProceedings{Korycki:2018ensdiv, author={{\L}. {Korycki} and B. {Krawczyk}}, booktitle={{2018 IEEE International Conference on Big Data (Big Data)}}, title={{Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams}}, year={2018}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/alsl2.png" class="thumbnail img-responsive"
                                                alt="Combining Active Learning and Self-Labeling for Data Stream Mining"><br>
                    </div>

                </div>

                <div class="col-sm-5 text-left slideanim-hor">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50" target="_blank" style="text-decoration: none">
                        <h4 class="mark hvr-fade"><strong>Combining Active Learning and Self-Labeling for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        In this work, we concentrate on the issue of the actual availability of true class labels. The assumption that the ground truth for each instance becomes known right after processing it is far from being realistic, due to usually high costs connected with its acquisition. Active learning is an attractive solution to this problem, as it selects the most valuable instances for labeling. We propose to augment the active learning module with the self-labeling approach. This allows a classifier to automatically label instances for which it displays the highest certainty and use them for further training. Although in this preliminary work we use a static threshold for self-labeling, the obtained results are encouraging. Our experimental study shows that this approach complements the active learning strategy and allows to improve data stream classification, especially in scenarios with a very small labeling budget.
                    </h4>
                    <h4 class="text-danger"><strong>International Conference on Computer Recognition Systems (CORES), Wrocław, Poland, 2017.</strong><br>
                        <a href=https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50 target="_blank" style="text-decoration: none"><button class="button">Paper</button></a>
                        <button class="button" data-clipboard-text=
                            "@InProceedings{Korycki:2018alsl, author={{\L}. {Korycki} and B. {Krawczyk}}, title={{Combining Active Learning and Self-Labeling for Data Stream Mining}}, booktitle={{Proceedings of the 10th International Conference on Computer Recognition Systems CORES 2017}}, year={2018}}"
                        >BibTex
                        </button>
                    </h4>
                    <br>
                </div>
            </div>

        </div>
    </div>

    <div id="projects" class="container-fluid bg-grey">
        <div class="major center slideanim-hor"><h2>PROJECTS</h2></div>
        <div class="row slideanim-hor">
            <h1 class="text-center">Coming soon!</h1><br>
        </div>
    </div>

    <footer class="container-fluid text-center">
        <script>
            document.body.classList.add('js-loading');
            window.addEventListener("load", showPage);
            function showPage() {
                document.body.classList.remove('js-loading');
            }

            $(window).on("load",function(){
                $(".loader-wrapper").fadeOut(200);
            });

            $(document).ready(function () {
                // var now = new Date().getTime();
                // while(new Date().getTime() < now + 1000){ /* do nothing */ }

                $(".navbar a, footer a[href='#home']").on('click', function (event) {
                    var hash = this.hash;
                    if (hash != "") {
                        event.preventDefault();
                    }

                    $('html, body').stop().animate({
                        scrollTop: $(hash).offset().top
                    }, 900, function () {
                        // window.location.hash = hash;
                    });
                });

                $(window).scroll(function () {
                    $(".slideanim-vert").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-vert");
                        }
                    });

                    $(".slideanim-hor").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-hor");
                        }
                    });
                });

                $(".slideanim-hor-init").each(async function () {
                    await new Promise(r => setTimeout(r, 400));
                    $(this).addClass("slide-hor");
                });

                $(".slideanim-hor-init-rev").each(async function () {
                    await new Promise(r => setTimeout(r, 400));
                    $(this).addClass("slide-hor-rev");
                });
            });

            function setTooltip(btn, message) {
                $(btn).tooltip('hide').tooltip({
                    trigger: 'click',
                    placement: 'right'
                }).attr('data-original-title', message).tooltip('show');
            }

            function hideTooltip(btn) {
                setTimeout(function() {
                    $(btn).tooltip('destroy');
                }, 1000);
            }

            // Clipboard
            var clipboard = new Clipboard('button');

            clipboard.on('success', function(e) {
                const el = document.createElement('textarea');
                el.value = e.text.replace(",", ",\n\t").replace(/},/g, '},\n\t').replace(/}$/g, '\n}');

                console.log(el.value);

                document.body.appendChild(el);
                el.select();
                document.execCommand('copy');
                document.body.removeChild(el);

                setTooltip(e.trigger, 'Copied to clipboard!');
                hideTooltip(e.trigger);
            });

            clipboard.on('error', function(e) {
                setTooltip(e.trigger, 'Failed!');
                hideTooltip(e.trigger);
            });

        </script>

        <a href="#home" title="Home">
            <span class="glyphicon glyphicon-home" style="font-size: 40px; color:white"></span>
        </a>
        <hr>
    </footer>

</body>
</html>
