<!DOCTYPE html>
<html lang="en">
<head>
    <title>Łukasz Korycki</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./css/academicons.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <link rel="stylesheet" href="./css/main.css" />

    <script src="https://kit.fontawesome.com/168639ce6f.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
</head>

<body id="body" data-spy="scroll" data-target=".navbar" data-offset="300">

    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#home">Łukasz Korycki</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#home">HOME</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#about">ME</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#events">EVENTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#research">RESEARCH</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="#projects">PROJECTS</a></li>
                    <li data-toggle="collapse" data-target=".navbar-collapse.in"><a href="data/Korycki_resume.pdf" target="_blank">CV</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="jumbotron" id="home">
        <div class="row">
            <div class="text-center">
                <div class="intro-anim-header delay200"><h1>Łukasz Korycki</h1></div>
                <div class="intro-anim-header delay600"><h3>PhD Student in ML/AI & Data Engineer</h3></div>
                <br>
                <a href="https://www.linkedin.com/in/%C5%82ukasz-korycki-6062ab195/" target="_blank">
                    <i class="fab fa-linkedin intro-anim-header delay100off" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://www.researchgate.net/profile/Lukasz_Korycki2" target="_blank">
                    <i class="ai ai-researchgate-square intro-anim-header delay200off" style="font-size:48px;color:#22e5a4"></i></a></a>
                <a href="https://scholar.google.com/citations?user=cLtlBLgAAAAJ&hl=en" target="_blank">
                    <i class="ai ai-google-scholar-square intro-anim-header delay300off" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://twitter.com" target="_blank">
                    <i class="fa fa-twitter-square intro-anim-header delay400off" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="https://github.com/lkorycki" target="_blank">
                    <i class="fa fa-github-square intro-anim-header delay500off" style="font-size:48px;color:#22e5a4"></i></a>
                <a href="korycki.lukas@gmail.com" target="_blank">
                    <i class="fa fa-envelope-square intro-anim-header delay600off" style="font-size:48px;color:#22e5a4"></i></a>
            </div>
        </div>
    </div>

    <div id="about" class="container-fluid slideanim-hor">
        <div class="row">
            <div class="col-sm-6 col-sm-offset-2">
                <div class="major"><h2>About Me</h2></div>
                <h4>Interested in discovering novel data mining algorithms and working with cutting-edge technologies that can be utilized in this domain.
                    Currently focused on advancing online learning algorithms that are able to effectively aggregate stable patterns and adapt to changes in dynamic environments.
                    Devoted to developing universal approaches and supporting their applications to real-world issues.
                    <br><br>
                    At the same time, a software and data engineer with relevant experience from the big data industry, aware of practical limitations and everyday challenges that come with complex data-driven commercial projects.
                </h4>
            </div>
            <div class="col-sm-2">
                <br><br>
                <span class="photo"><img src="images/photo.png"></span>
            </div>
        </div>
    </div>

    <div id="events" class="container-fluid bg-grey slideanim-hor">
        <div class="row">
            <div class="col-sm-8 col-sm-offset-2">
                <div class="major center"><h2>Events</h2></div>
<!--                <h4><strong>Jan 2020:</strong> Lorem ipsum.</h4>-->
<!--                <h4><strong>Jun 2020:</strong>  Lorem ipsum.</h4>-->
            </div>
        </div>

        <div class="page">
            <div class="timeline">

<!--                <div class="timeline__group">-->
<!--                    <span class="timeline__year">Now</span>-->
<!--                </div>-->

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Received a conference registration grant and was accepted to the early career mentoring program at IJCNN!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">20</span>
                            <span class="timeline__month">Mar</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams target="_blank">"Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"</a> was accepted for presentation at IJCNN 2020!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2020</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">16</span>
                            <span class="timeline__month">Dec</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Passed the Ph.D. Qualifying Exam.</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">06</span>
                            <span class="timeline__month">Oct</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank">"Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2019 (acceptance rate: 18.7%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">27</span>
                            <span class="timeline__month">Jul</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8964214 target="_blank">"Unsupervised Drift Detector Ensembles for Data Stream Mining"</a> was accepted for presentation at IEEE DSAA 2019 (acceptance rate: 29.4%)!</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2019</span>
                </div>

                <div class="timeline__group">
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">28</span>
                            <span class="timeline__month">Aug</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Our paper <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank">"Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"</a> was accepted for presentation at IEEE Big Data 2018 (acceptance rate: 18.9%)!</p>
                            </div>
                        </div>
                    </div>
                    <div class="timeline__box">
                        <div class="timeline__date">
                            <span class="timeline__day">08</span>
                            <span class="timeline__month">Jan</span>
                        </div>
                        <div class="timeline__post">
                            <div class="timeline__content">
                                <p>Started working in the Machine Learning and Data Stream Mining Lab at Virginia Commonwealth University (Richmond, USA) under Dr. Bartosz Krawczyk.</p>
                            </div>
                        </div>
                    </div>
                    <span class="timeline__year">2018</span>
                </div>
            </div>
        </div>

    </div>

    <div id="research">
        <div class="container-fluid slideanim-hor">
            <div class="major center"><h2>Research</h2></div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/os_imb.png" class="thumbnail img-responsive"
                                                alt="Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank">
                        <h4 class="mark"><strong>Online Oversampling for Sparsely Labeled Imbalanced and Non-Stationary Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Learning from imbalanced data and data stream mining are among most popular areas in contemporary machine learning. There is a strong interplay between these domains, as data streams are frequently characterized by skewed distributions. However, most of existing works focus on binary problems, omitting significantly more challenging multi-class imbalanced data. In this paper, we propose a novel framework for learning from multi-class imbalanced data streams that simultaneously tackles three major problems in this area: (i) changing imbalance ratios among multiple classes; (ii) concept drift; and (iii) limited access to ground truth. We use active learning combined with streaming-based oversampling that uses both information about current class ratios and classifier errors on each class to create new instances in a meaningful way. Conducted experimental study shows that our single-classifier framework is capable of outperforming state-of-the-art ensembles dedicated to multi-class imbalanced data streams in both fully supervised and sparsely labeled learning scenarios.                    </h4>
                    <h4 class="text-danger"><strong> International Joint Conference on Neural Networks (IJCNN), Glasgow, UK, 2020. </strong><br>
                        <a href="https://www.researchgate.net/publication/341463040_Online_Oversampling_for_Sparsely_Labeled_Imbalanced_and_Non-Stationary_Data_Streams" target="_blank"><kbd>Paper</kbd></a>
                        <kbd data-toggle="collapse" data-target="#temp">Bibtex</kbd>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/abst4.png" class="thumbnail img-responsive"
                                                alt="Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://ieeexplore.ieee.org/document/9006453" target="_blank">
                        <h4 class="mark"><strong>Active Learning with Abstaining Classifiers for Imbalanced Drifting Data Streams</strong><br>
                            <small><strong>Ł. Korycki</strong>, A.Cano, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">Learning from data streams is one of the most promising and challenging domains in modern machine learning. Proliferating online data sources provide us access to real-time knowledge we have never had before. At the same time, new obstacles emerge and we have to overcome them in order to fully and effectively utilize the potential of the data. Prohibitive time and memory constraints or non-stationary distributions are only some of the problems. When dealing with classification tasks, one has to remember that effective adaptation has to be achieved on weak foundations of partially labeled and often imbalanced data. In our work, we propose an online framework for binary classification, that aims to handle the complex problem of working with dynamic, sparsely labeled and imbalanced streams. The main part of it is a novel active learning strategy (MD-OAL) that is able to prioritize labeling of minority instances and, as a result, improve the balance of the learning process. We combine the strategy with a dynamic ensemble of base learners that can abstain from making decisions, if they are very uncertain. We adjust the abstaining mechanism in favor of minority instances, providing an effective method for handling remaining imbalance and a concept drift simultaneously. The conducted evaluation shows that in the challenging and realistic scenarios our framework outperforms state-of-the-art algorithms, providing higher resilience to the combined effect of limited labeling and imbalance.</h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/9006453 target="_blank"><kbd>Paper</kbd></a>
                        <kbd data-toggle="collapse" data-target="#temp">Bibtex</kbd>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/ens_det.jpg" class="thumbnail img-responsive"
                                                alt="Unsupervised Drift Detector Ensembles for Data Stream Mining"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank">
                        <h4 class="mark"><strong>Unsupervised Drift Detector Ensembles for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">
                        Data stream mining is among the most contemporary branches of machine learning. The potentially infinite sources give us many opportunities and at the same time pose new challenges. To properly handle streaming data we need to improve our well-established methods, so they can work with dynamic data and under strict constraints. Supervised streaming machine learning algorithms require a certain number of labeled instances in order to stay up-to-date. Since high budgets dedicated for this purpose are usually infeasible, we have to limit the supervision as much as we can. One possible approach is to trigger labeling, only if a change is explicitly indicated by a detector. While there are several supervised algorithms dedicated for this purpose, the more practical unsupervised ones are still lacking a proper attention. In this paper, we propose a novel unsupervised ensemble drift detector that recognizes local changes in feature subspaces (EDFS) without additional supervision, using specialized committees of incremental Kolmogorov-Smirnov tests. We combine it with an adaptive classifier and update it, only if the drift detector signalizes a change. Conducted experiments show that our framework is able to efficiently adapt to various concept drifts and outperform other unsupervised algorithms.
                    </h4>
                    <h4 class="text-danger"><strong> IEEE International Conference on Data Science and Advanced Analytics DSAA, Washington, D.C., USA, 2019.</strong><br>
                        <a href="https://ieeexplore.ieee.org/abstract/document/8964214" target="_blank"><kbd>Paper</kbd></a>
                        <kbd data-toggle="collapse" data-target="#temp">Bibtex</kbd>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <div class="slideanim-vert"><img src="images/clust_divers.jpg" class="thumbnail img-responsive"
                                                alt="Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://ieeexplore.ieee.org/document/8622038" target="_blank">
                        <h4 class="mark"><strong>Clustering-Driven and Dynamically Diversified Ensemble for Drifting Data Streams</strong><br>
                        <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a><h4 class="h4-small">
                        Data stream mining is a rapidly developing branch of contemporary machine learning. Ensemble approaches have proven themselves to be highly effective in this domain, due to their  predictive  power  and  capabilities  for  handling  evolving data.  One  of  the  key  aspects  of  ensemble  learning  is  diversity among  base  classifiers  –  it  improves  accuracy  and  allows  for anticipating  and  recovering  from  concept  drifts.  It  has  been shown that while diversity is desirable during changes, it may impede  learning  when  data  becomes  stationary.  In  this  paper, we  present  a  novel  ensemble  technique  that  exploits  the  idea of  dynamic  diversification,  which  increases  diversity  during changes  and  reduces  it  when  a  stream  becomes  stable.  The algorithm uses online clustering for this task by creating locally specialized base learners trained on spatially related instances. Three control strategies based on the novel range heuristic for managing  a  trade-off  between  error  (a  change  indicator)  and diversity are utilized. Additionally, two intensification strategies are  proposed  for  exploitation  of  newly  arriving  instances,  allowing for faster adaptation. Experimental study evaluates the general performance and diversity of the proposed algorithm, proving its capabilities to outperform state-of-the-art ensembles dedicated  to  drifting  data  stream  mining.</h4>
                    <h4 class="text-danger"><strong>IEEE International Conference on Big Data (Big Data), Seattle, WA, USA, 2018.</strong><br>
                        <a href=https://ieeexplore.ieee.org/document/8622038 target="_blank"><kbd>Paper</kbd></a>
                        <kbd data-toggle="collapse" data-target="#temp">Bibtex</kbd>
                    </h4>
                    <br>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-3 col-sm-offset-2">
                    <br>
                    <div class="slideanim-vert"><img src="images/alsl2.png" class="thumbnail img-responsive"
                                                alt="Combining Active Learning and Self-Labeling for Data Stream Mining"><br>
                    </div>
                </div>

                <div class="col-sm-5 text-left">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50" target="_blank">
                        <h4 class="mark"><strong>Combining Active Learning and Self-Labeling for Data Stream Mining</strong><br>
                            <small><strong>Ł. Korycki</strong>, B. Krawczyk<br></small></h4></a>
                    <h4 class="h4-small">Data stream mining is among the most vital contemporary data science challenges. In this work we concentrate on the issue of actual availability of true class labels. Assumption that the ground truth for each instance becomes known right after processing it is far from being realistic, due to usually high costs connected with its acquisition. Active learning is an attractive solution to this problem, as it selects most valuable instances for labeling. In this paper, we propose to augment the active learning module with self-labeling approach. This allows classifier to automatically label instances for which it displays the highest certainty and use them for further training. Although in this preliminary work we use a static threshold for self-labeling, the obtained results are encouraging. Our experimental study shows that this approach complements the active learning strategy and allows to improve data stream classification, especially in scenarios with very small labeling budget.</h4>
                    <h4 class="text-danger"><strong>International Conference on Computer Recognition Systems (CORES), Wrocław, Poland, 2017.</strong><br>
                        <a href=https://link.springer.com/chapter/10.1007/978-3-319-59162-9_50 target="_blank"><kbd>Paper</kbd></a>
                        <kbd data-toggle="collapse" data-target="#temp">Bibtex</kbd>
                    </h4>
                    <br>
                </div>
            </div>

        </div>
    </div>

    <div id="projects" class="container-fluid bg-grey slideanim-hor">
        <div class="major center"><h2>PROJECTS</h2></div>
        <div class="row">
            <h1 class="text-center">Coming soon!</h1><br>
        </div>
    </div>

    <footer class="container-fluid text-center">
        <script>
            $(document).ready(function () {
                // Add smooth scrolling to all links in navbar + footer link
                $(".navbar a, footer a[href='#home']").on('click', function (event) {
                    var hash = this.hash;
                    if (hash != "") {
                        event.preventDefault();
                    }

                    // Using jQuery's animate() method to add smooth page scroll
                    // The optional number (900) specifies the number of milliseconds it takes to scroll to the specified area
                    $('html, body').stop().animate({
                        scrollTop: $(hash).offset().top
                    }, 900, function () {

                        // Add hash (#) to URL when done scrolling (default click behavior)
                        window.location.hash = hash;
                    });
                });

                $(window).scroll(function () {
                    $(".slideanim-vert").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-vert");
                        }
                    });

                    $(".slideanim-hor").each(function () {
                        var pos = $(this).offset().top;
                        var winTop = $(window).scrollTop();
                        if (pos < winTop + 800) {
                            $(this).addClass("slide-hor");
                        }
                    });
                });
            })
        </script>

        <a href="#home" title="To Top">
            <span class="glyphicon glyphicon-home" style="font-size: 40px; color:white"></span>
        </a>
        <hr>
    </footer>

</body>
</html>
